{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/gf332/compression_venv/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/scratch/gf332/compression_venv/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/scratch/gf332/compression_venv/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/scratch/gf332/compression_venv/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/scratch/gf332/compression_venv/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/scratch/gf332/compression_venv/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/scratch/gf332/compression_venv/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/scratch/gf332/compression_venv/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/scratch/gf332/compression_venv/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/scratch/gf332/compression_venv/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/scratch/gf332/compression_venv/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/scratch/gf332/compression_venv/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"/homes/gf332/compression-without-quantization/code\")\n",
    "\n",
    "import os, glob\n",
    "from tqdm import tqdm as tqdm\n",
    "\n",
    "import tensorflow.compat.v1 as tf\n",
    "import tensorflow_compression as tfc\n",
    "import tensorflow_probability as tfp\n",
    "import tensorflow.contrib.eager as tfe\n",
    "tfd = tfp.distributions\n",
    "tfk = tf.keras\n",
    "tfl = tf.keras.layers\n",
    "tfq = tf.quantization\n",
    "\n",
    "from binary_io import to_bit_string, from_bit_string\n",
    "\n",
    "from pln import ProbabilisticLadderNetwork\n",
    "from vae import VariationalAutoEncoder\n",
    "\n",
    "from miracle import create_dataset, quantize_image, read_png\n",
    "\n",
    "from coded_greedy_sampler import code_grouped_greedy_sample, decode_grouped_greedy_sample\n",
    "from coded_importance_sampler import code_grouped_importance_sample, decode_grouped_importance_sample\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'code_grouped_greedy_sample_' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-aab768a41278>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m#     samp = sess.run(res)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     res = code_grouped_greedy_sample_(sess=sess,\n\u001b[0m\u001b[1;32m     32\u001b[0m                                     \u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mq1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                                    \u001b[0mproposal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'code_grouped_greedy_sample_' is not defined"
     ]
    }
   ],
   "source": [
    "n_bits_per_step = 14\n",
    "n_steps = 30\n",
    "seed = 42\n",
    "rho = 1.\n",
    "first_level_max_group_size_bits=12\n",
    "second_level_max_group_size_bits=4\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "\n",
    "#     res = code_greedy_sample_(t_loc=q1_loc,\n",
    "#                               t_scale=q1_scale,\n",
    "#                               p_loc=p1_loc,\n",
    "#                               p_scale=p1_scale,\n",
    "#                                 n_bits_per_step=14, \n",
    "#                                 n_steps=30, \n",
    "#                                 seed=seed, \n",
    "#                                 rho=1.)\n",
    "    \n",
    "#     bs, si = sess.run(res)\n",
    "    \n",
    "#     res = decode_greedy_sample_(sample_index=si, \n",
    "#                                   p_loc=p1_loc,\n",
    "#                                   p_scale=p1_scale,\n",
    "#                                   n_bits_per_step=14, \n",
    "#                                   n_steps=30, \n",
    "#                                   seed=seed, \n",
    "#                                   rho=1.)\n",
    "#     samp = sess.run(res)\n",
    "\n",
    "    res = code_grouped_greedy_sample_(sess=sess,\n",
    "                                    target=q1, \n",
    "                                   proposal=p1,\n",
    "                                   n_steps=n_steps, \n",
    "                                   n_bits_per_step=n_bits_per_step,\n",
    "                                   seed=seed,\n",
    "                                   max_group_size_bits=12,\n",
    "                                   adaptive=True,\n",
    "                                   backfitting_steps=0,\n",
    "                                   use_log_prob=False,\n",
    "                                   rho=1.)\n",
    "    \n",
    "    sample, bitcode, group_start_indices = res\n",
    "    \n",
    "    dec = decode_grouped_greedy_sample_(sess=sess,\n",
    "                                  bitcode=bitcode, \n",
    "                                 group_start_indices=group_start_indices,\n",
    "                                 proposal=p1, \n",
    "                                 n_bits_per_step=n_bits_per_step, \n",
    "                                 n_steps=n_steps, \n",
    "                                 seed=seed,\n",
    "                                 adaptive=True,\n",
    "                                 rho=1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'01010101010'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = b\"01010\"\n",
    "x2 = b\"101010\"\n",
    "\n",
    "x1.decode(\"utf-8\") + x2.decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pln = ProbabilisticLadderNetwork(first_level_filters=196,\n",
    "                 second_level_filters=128,\n",
    "                 first_level_latent_channels=96,\n",
    "                 second_level_latent_channels=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=1579, shape=(1, 256, 256, 3), dtype=float32, numpy=\n",
       "array([[[[-1.6792757e-02,  2.2184392e-03,  1.9746967e-02],\n",
       "         [ 6.6196052e-03, -2.2168769e-02, -1.6886838e-02],\n",
       "         [-2.1191034e-02, -2.8058609e-02,  7.4476851e-03],\n",
       "         ...,\n",
       "         [-1.0100249e-03,  3.9053417e-03, -7.7782874e-03],\n",
       "         [ 5.2362448e-03,  5.4826005e-04, -5.9118317e-03],\n",
       "         [ 2.3379992e-04,  3.7516505e-03,  2.7051612e-03]],\n",
       "\n",
       "        [[-1.3277968e-02, -2.2607055e-02,  3.9487528e-03],\n",
       "         [ 2.4542399e-03, -2.4774945e-03, -1.4310884e-03],\n",
       "         [-2.9393932e-02,  1.3712058e-02, -2.8937060e-02],\n",
       "         ...,\n",
       "         [-3.3044368e-03,  8.9179445e-03, -6.7474688e-03],\n",
       "         [ 7.3202178e-03, -5.6522200e-03,  2.7930634e-03],\n",
       "         [ 9.4084884e-04,  3.5936534e-03,  3.3889655e-03]],\n",
       "\n",
       "        [[ 4.1583637e-03, -1.6088195e-02, -3.2119947e-03],\n",
       "         [-2.8121158e-02, -1.2608425e-02,  8.1854174e-04],\n",
       "         [-1.9442908e-02, -7.2216660e-02, -8.9343907e-03],\n",
       "         ...,\n",
       "         [ 2.6113896e-03, -6.5063452e-03, -1.2173806e-02],\n",
       "         [-4.4623269e-03,  1.5782548e-02,  1.7894952e-02],\n",
       "         [-8.2911076e-03, -9.7391242e-03,  5.8133882e-03]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-1.3690712e-03,  1.2271969e-03,  1.4440655e-03],\n",
       "         [ 1.1251652e-02, -6.0986954e-04, -6.1864969e-03],\n",
       "         [ 9.2401635e-03, -1.3442690e-02, -2.9924935e-02],\n",
       "         ...,\n",
       "         [ 1.0506791e-03,  1.9929577e-03, -4.1102641e-03],\n",
       "         [-8.3657075e-03,  1.0961220e-03, -3.3885641e-03],\n",
       "         [-2.2353779e-04, -3.3298275e-06, -2.3121343e-03]],\n",
       "\n",
       "        [[ 6.5190620e-03,  1.2607591e-02, -1.8908153e-04],\n",
       "         [ 6.0713347e-03, -1.7462543e-04, -9.8457932e-03],\n",
       "         [-4.0358272e-03,  9.2066191e-03,  5.6042704e-03],\n",
       "         ...,\n",
       "         [-1.6890437e-03, -2.4862534e-03, -2.8880872e-03],\n",
       "         [ 8.2626715e-03, -6.0806572e-03,  2.7149545e-03],\n",
       "         [ 6.6413224e-05,  3.5741425e-04, -6.6536758e-04]],\n",
       "\n",
       "        [[ 3.5374539e-04, -3.8095179e-04, -1.3203288e-03],\n",
       "         [ 1.8329867e-03, -6.2033441e-03,  3.5674446e-03],\n",
       "         [ 7.4005169e-03,  7.2384188e-03, -6.7104166e-03],\n",
       "         ...,\n",
       "         [ 8.9678296e-04,  6.0692412e-04, -7.0270675e-04],\n",
       "         [ 1.5078550e-03,  3.8583125e-03,  1.9989961e-03],\n",
       "         [-1.2070297e-03,  1.5717749e-03,  1.2820832e-03]]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pln(tf.zeros((1, 256, 256, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 16, 16, 96)\n",
      "(1, 4, 4, 24)\n",
      "(1, 16, 16, 96)\n",
      "(1, 4, 4, 24)\n"
     ]
    }
   ],
   "source": [
    "print(pln.posterior_1.loc.shape)\n",
    "print(pln.posterior_2.loc.shape)\n",
    "print(pln.prior_1.loc.shape)\n",
    "print(pln.prior_2.loc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
